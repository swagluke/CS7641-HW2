{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "NeuralNetwork-SimulatedAnnealing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej2302_t0YDb",
        "outputId": "111ef4b0-6c9c-4e13-c857-135e8cb452ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install mlrose_hiive\n",
        "\n",
        "import time\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from sklearn.model_selection import train_test_split\n",
        "pd.options.display.max_columns = None\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.rc('figure', figsize=[10,5])\n",
        "import mlrose_hiive\n",
        "from mlrose_hiive import ExpDecay\n",
        "from sklearn.metrics import f1_score\n",
        "from functools import partial\n",
        "from google.colab import drive\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mlrose_hiive\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/ba/75f9e6b421a8a7fc1bb91ee72d5ae27fe381828d8df7fc0869654b295729/mlrose_hiive-2.1.3.tar.gz (48kB)\n",
            "\r\u001b[K     |██████▊                         | 10kB 14.1MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mlrose_hiive) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from mlrose_hiive) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from mlrose_hiive) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from mlrose_hiive) (1.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from mlrose_hiive) (2.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from mlrose_hiive) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->mlrose_hiive) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->mlrose_hiive) (2018.9)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->mlrose_hiive) (4.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->mlrose_hiive) (1.15.0)\n",
            "Building wheels for collected packages: mlrose-hiive\n",
            "  Building wheel for mlrose-hiive (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mlrose-hiive: filename=mlrose_hiive-2.1.3-cp36-none-any.whl size=96601 sha256=5206a317739b0623bd33671dc79bc54e3aa57afd96b1eb701b1bd3201ce67413\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/ef/8b/941402c2014649279f68a1ed4a37b4d15142dfb9c7e4a6b7ac\n",
            "Successfully built mlrose-hiive\n",
            "Installing collected packages: mlrose-hiive\n",
            "Successfully installed mlrose-hiive-2.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eaX3W1e0YDe"
      },
      "source": [
        "np.random.seed(44)\n",
        "train_data = pd.read_csv('sample_data/mnist_train_small.csv')\n",
        "test_data = pd.read_csv('sample_data/mnist_test.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwOhjoKI0YDh"
      },
      "source": [
        "train_y = train_data['6']\n",
        "train_y.columns = ['label']\n",
        "test_y = test_data['7']\n",
        "test_y.columns = ['label']\n",
        "train_X = train_data.drop(columns = ['6'])\n",
        "test_X = test_data.drop(columns = ['7'])\n",
        "\n",
        "feature_names = []\n",
        "for i in range(len(train_X.columns)):\n",
        "    feature_names.append(i)\n",
        "\n",
        "train_X.columns = feature_names\n",
        "test_X.columns = feature_names "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibJDRRvQ0YDo",
        "outputId": "ed0dcc26-83a4-48fa-9738-441f64ef1ea9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "start_time = time.time()\n",
        "\n",
        "f1_labs = partial(f1_score, average=\"weighted\")\n",
        "grid_search_parameters = ({\n",
        "  'schedule': [ExpDecay(1),ExpDecay(10),ExpDecay(25),ExpDecay(50), ExpDecay(100),ExpDecay(10000)],\n",
        "  'learning_rate': [0.0001, 0.001, 0.0025, 0.005, 0.01],  \n",
        "  'activation': [mlrose_hiive.neural.activation.relu],\n",
        "  'max_iters': [1000]\n",
        "})\n",
        "nnr = mlrose_hiive.NNGSRunner(x_train=train_X,\n",
        "                     y_train=pd.get_dummies(train_y.values.ravel()).values,\n",
        "                     x_test=test_X,\n",
        "                     y_test=pd.get_dummies(test_y.values.ravel()).values,\n",
        "                     experiment_name='nn_test',\n",
        "                     seed=10,\n",
        "                     output_directory=\"./sa\",\n",
        "                     hidden_layer_sizes=[[60,60]],                             \n",
        "                     algorithm=mlrose_hiive.algorithms.sa.simulated_annealing,\n",
        "                     grid_search_parameters=grid_search_parameters,\n",
        "                     grid_search_scorer_method=f1_labs,\n",
        "                     iteration_list=[1000],\n",
        "                     n_jobs=-2)\n",
        "results = nnr.run()   \n",
        "\n",
        "end_time = time.time()\n",
        "run_time = end_time - start_time\n",
        "\n",
        "print(\"Simulated Annealing Run time: \" + str(run_time))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running nngs_sa\n",
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.34], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.80], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.19], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.28], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.12], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.29], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.26], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.24], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[44.92], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.06], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.85], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.00], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.96], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.29], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.07], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.42], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.88], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.27], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.95], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.17], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.29], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.00], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.71], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.47], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.84], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.39], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[44.83], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.57], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.78], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.89], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.78], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.03], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.24], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.87], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.80], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.94], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.24], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.22], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.24], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.26], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.15], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.14], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.86], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.27], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.75], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.17], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.24], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.37], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.27], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.08], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.24], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.97], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.11], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.11], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.43], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[44.76], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.29], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[44.78], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.27], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[47.46], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.28], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.60], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.27], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.76], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[47.07], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.58], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.77], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.27], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.53], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.28], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.71], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.27], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.45], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.90], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[47.20], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[47.16], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.36], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.27], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.76], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.24], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.47], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.15], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.50], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.20], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.24], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.31], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.61], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.24], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.93], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.27], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.10], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.39], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.24], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.19], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.21], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.47], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.05], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[44.94], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.24], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.91], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.28], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.45], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[44.49], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.12], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.24], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[43.61], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.78], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[44.90], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.24], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.39], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.86], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[44.84], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.24], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.19], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.99], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.20], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.81], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[44.76], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.24], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.88], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.24], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[48.19], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.04], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.28], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[47.33], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.0025], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.55], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.82], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.98], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.09], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.28], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[47.69], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.27], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.14], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[47.78], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[47.27], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[47.30], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[47.60], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.27], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.34], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[47.25], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.24], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[47.17], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.28], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[47.19], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[47.33], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.43], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.31], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.88], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.55], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.24], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.56], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.22], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.27], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[44.59], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.67], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.39], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.24], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.78], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.40], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.44], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[44.89], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.31], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.24], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.24], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.29], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.06], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.45], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.005], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[44.56], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.25], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.07], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.24], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.99], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.86], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.61], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.52], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.29], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[47.31], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[47.73], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[47.61], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.15], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[47.34], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.22], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.02], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.30], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[47.93], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.56], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[25], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[47.05], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[47.58], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[48.22], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[48.19], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[47.57], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[50], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.24], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[47.44], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.31], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.87], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.26], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.32], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[46.88], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[100], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[44.39], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3781]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.20], fitness:[31.4136]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.3472]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.04], fitness:[31.3671]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.25], fitness:[31.3325]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.21], fitness:[31.3561]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.23], fitness:[31.3213]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[45.63], fitness:[31.3365]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.24], fitness:[31.4191]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[10000], learning_rate:[0.01], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[44.78], fitness:[31.4398]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 150 out of 150 | elapsed: 122.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*****************\n",
            "*** Run START ***\n",
            "*****************\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[0], iteration:[0], done:[False], time:[0.32], fitness:[31.3596]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "max_iters:[100], schedule:[1], learning_rate:[0.0001], init_state:[[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159\n",
            "  0.99258313]], algorithm:[sa], activation:[relu], bias:[True], early_stopping:[True], clip_max:[10000000000.0], hidden_layer_sizes:[[60, 60]], learning_rate_init:[0.1], max_attempts:[500]\n",
            "runner_name:[nngs_sa], experiment_name:[nn_test], attempt:[1], iteration:[100], done:[True], time:[55.59], fitness:[31.3748]\n",
            "\t[ 0.54264129 -0.9584961   0.26729647 ...  0.98872842  0.15632159//  0.99258313]...\n",
            "\n",
            "***************\n",
            "*** Run END ***\n",
            "***************\n",
            "Run time: 7429.313205753\n",
            "Saving: [./sa/nn_test/nngs_sa__nn_test__run_stats_df__0E87E9CDB8F2B1D83C7F33C11F3C92DA.csv]\n",
            "Saving: [./sa/nn_test/nngs_sa__nn_test__curves_df__0E87E9CDB8F2B1D83C7F33C11F3C92DA.csv]\n",
            "Saving: [./sa/nn_test/nngs_sa__nn_test__cv_results_df__0E87E9CDB8F2B1D83C7F33C11F3C92DA.csv]\n",
            "Saving: [./sa/nn_test/nngs_sa__nn_test__grid_search_results__0E87E9CDB8F2B1D83C7F33C11F3C92DA.p]\n",
            "Simulated Annealing Run time: 7436.43891787529\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3f8pPDT0YDr",
        "outputId": "668ee9b9-a70f-4bfb-cf37-44dea75e389e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "results[2]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_activation</th>\n",
              "      <th>param_hidden_layer_sizes</th>\n",
              "      <th>param_learning_rate</th>\n",
              "      <th>param_max_iters</th>\n",
              "      <th>param_schedule</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>split3_train_score</th>\n",
              "      <th>split4_train_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>48.487795</td>\n",
              "      <td>0.515139</td>\n",
              "      <td>0.066798</td>\n",
              "      <td>0.003554</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>48.400264</td>\n",
              "      <td>0.360022</td>\n",
              "      <td>0.061462</td>\n",
              "      <td>0.004883</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100</td>\n",
              "      <td>10</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>48.487125</td>\n",
              "      <td>0.479855</td>\n",
              "      <td>0.058810</td>\n",
              "      <td>0.001101</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100</td>\n",
              "      <td>25</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>48.247758</td>\n",
              "      <td>0.530896</td>\n",
              "      <td>0.062395</td>\n",
              "      <td>0.004121</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100</td>\n",
              "      <td>50</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>48.223431</td>\n",
              "      <td>0.329084</td>\n",
              "      <td>0.060366</td>\n",
              "      <td>0.001721</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>48.487396</td>\n",
              "      <td>0.392964</td>\n",
              "      <td>0.061794</td>\n",
              "      <td>0.003064</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100</td>\n",
              "      <td>10000</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>48.421458</td>\n",
              "      <td>0.351178</td>\n",
              "      <td>0.059842</td>\n",
              "      <td>0.001391</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>48.543551</td>\n",
              "      <td>0.415789</td>\n",
              "      <td>0.061587</td>\n",
              "      <td>0.002681</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>100</td>\n",
              "      <td>10</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>48.503658</td>\n",
              "      <td>1.091594</td>\n",
              "      <td>0.059788</td>\n",
              "      <td>0.000658</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>100</td>\n",
              "      <td>25</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>49.185748</td>\n",
              "      <td>0.496232</td>\n",
              "      <td>0.060087</td>\n",
              "      <td>0.000887</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>100</td>\n",
              "      <td>50</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>49.452220</td>\n",
              "      <td>0.335114</td>\n",
              "      <td>0.061905</td>\n",
              "      <td>0.001296</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>48.849985</td>\n",
              "      <td>0.553171</td>\n",
              "      <td>0.064216</td>\n",
              "      <td>0.003515</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>100</td>\n",
              "      <td>10000</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>48.713340</td>\n",
              "      <td>0.413031</td>\n",
              "      <td>0.061534</td>\n",
              "      <td>0.003133</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0025</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>48.587297</td>\n",
              "      <td>0.512617</td>\n",
              "      <td>0.060756</td>\n",
              "      <td>0.000848</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0025</td>\n",
              "      <td>100</td>\n",
              "      <td>10</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>47.730706</td>\n",
              "      <td>0.943170</td>\n",
              "      <td>0.064945</td>\n",
              "      <td>0.009196</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0025</td>\n",
              "      <td>100</td>\n",
              "      <td>25</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>47.985326</td>\n",
              "      <td>0.405182</td>\n",
              "      <td>0.062115</td>\n",
              "      <td>0.004458</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0025</td>\n",
              "      <td>100</td>\n",
              "      <td>50</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>48.823790</td>\n",
              "      <td>0.786029</td>\n",
              "      <td>0.063715</td>\n",
              "      <td>0.002553</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0025</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>49.647546</td>\n",
              "      <td>0.736701</td>\n",
              "      <td>0.083096</td>\n",
              "      <td>0.032718</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0025</td>\n",
              "      <td>100</td>\n",
              "      <td>10000</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>48.983949</td>\n",
              "      <td>0.678004</td>\n",
              "      <td>0.074801</td>\n",
              "      <td>0.024782</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>49.932725</td>\n",
              "      <td>0.482038</td>\n",
              "      <td>0.079645</td>\n",
              "      <td>0.031771</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>100</td>\n",
              "      <td>10</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>49.712844</td>\n",
              "      <td>0.331611</td>\n",
              "      <td>0.075638</td>\n",
              "      <td>0.018591</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>100</td>\n",
              "      <td>25</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>48.054905</td>\n",
              "      <td>0.469763</td>\n",
              "      <td>0.071520</td>\n",
              "      <td>0.010674</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>100</td>\n",
              "      <td>50</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>48.296250</td>\n",
              "      <td>0.511843</td>\n",
              "      <td>0.066989</td>\n",
              "      <td>0.015489</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>47.996280</td>\n",
              "      <td>0.484588</td>\n",
              "      <td>0.070348</td>\n",
              "      <td>0.017757</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>100</td>\n",
              "      <td>10000</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>49.019893</td>\n",
              "      <td>0.351815</td>\n",
              "      <td>0.059342</td>\n",
              "      <td>0.002649</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>49.543883</td>\n",
              "      <td>0.949828</td>\n",
              "      <td>0.066119</td>\n",
              "      <td>0.013293</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>100</td>\n",
              "      <td>10</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>49.648966</td>\n",
              "      <td>0.652167</td>\n",
              "      <td>0.065459</td>\n",
              "      <td>0.010479</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>100</td>\n",
              "      <td>25</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>50.231137</td>\n",
              "      <td>0.745615</td>\n",
              "      <td>0.070283</td>\n",
              "      <td>0.020046</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>100</td>\n",
              "      <td>50</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>48.690985</td>\n",
              "      <td>1.050621</td>\n",
              "      <td>0.066577</td>\n",
              "      <td>0.003675</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>47.848553</td>\n",
              "      <td>0.261756</td>\n",
              "      <td>0.063778</td>\n",
              "      <td>0.008756</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>100</td>\n",
              "      <td>10000</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "0       48.487795      0.515139         0.066798        0.003554   \n",
              "1       48.400264      0.360022         0.061462        0.004883   \n",
              "2       48.487125      0.479855         0.058810        0.001101   \n",
              "3       48.247758      0.530896         0.062395        0.004121   \n",
              "4       48.223431      0.329084         0.060366        0.001721   \n",
              "5       48.487396      0.392964         0.061794        0.003064   \n",
              "6       48.421458      0.351178         0.059842        0.001391   \n",
              "7       48.543551      0.415789         0.061587        0.002681   \n",
              "8       48.503658      1.091594         0.059788        0.000658   \n",
              "9       49.185748      0.496232         0.060087        0.000887   \n",
              "10      49.452220      0.335114         0.061905        0.001296   \n",
              "11      48.849985      0.553171         0.064216        0.003515   \n",
              "12      48.713340      0.413031         0.061534        0.003133   \n",
              "13      48.587297      0.512617         0.060756        0.000848   \n",
              "14      47.730706      0.943170         0.064945        0.009196   \n",
              "15      47.985326      0.405182         0.062115        0.004458   \n",
              "16      48.823790      0.786029         0.063715        0.002553   \n",
              "17      49.647546      0.736701         0.083096        0.032718   \n",
              "18      48.983949      0.678004         0.074801        0.024782   \n",
              "19      49.932725      0.482038         0.079645        0.031771   \n",
              "20      49.712844      0.331611         0.075638        0.018591   \n",
              "21      48.054905      0.469763         0.071520        0.010674   \n",
              "22      48.296250      0.511843         0.066989        0.015489   \n",
              "23      47.996280      0.484588         0.070348        0.017757   \n",
              "24      49.019893      0.351815         0.059342        0.002649   \n",
              "25      49.543883      0.949828         0.066119        0.013293   \n",
              "26      49.648966      0.652167         0.065459        0.010479   \n",
              "27      50.231137      0.745615         0.070283        0.020046   \n",
              "28      48.690985      1.050621         0.066577        0.003675   \n",
              "29      47.848553      0.261756         0.063778        0.008756   \n",
              "\n",
              "   param_activation param_hidden_layer_sizes  param_learning_rate  \\\n",
              "0              relu                 [60, 60]               0.0001   \n",
              "1              relu                 [60, 60]               0.0001   \n",
              "2              relu                 [60, 60]               0.0001   \n",
              "3              relu                 [60, 60]               0.0001   \n",
              "4              relu                 [60, 60]               0.0001   \n",
              "5              relu                 [60, 60]               0.0001   \n",
              "6              relu                 [60, 60]               0.0010   \n",
              "7              relu                 [60, 60]               0.0010   \n",
              "8              relu                 [60, 60]               0.0010   \n",
              "9              relu                 [60, 60]               0.0010   \n",
              "10             relu                 [60, 60]               0.0010   \n",
              "11             relu                 [60, 60]               0.0010   \n",
              "12             relu                 [60, 60]               0.0025   \n",
              "13             relu                 [60, 60]               0.0025   \n",
              "14             relu                 [60, 60]               0.0025   \n",
              "15             relu                 [60, 60]               0.0025   \n",
              "16             relu                 [60, 60]               0.0025   \n",
              "17             relu                 [60, 60]               0.0025   \n",
              "18             relu                 [60, 60]               0.0050   \n",
              "19             relu                 [60, 60]               0.0050   \n",
              "20             relu                 [60, 60]               0.0050   \n",
              "21             relu                 [60, 60]               0.0050   \n",
              "22             relu                 [60, 60]               0.0050   \n",
              "23             relu                 [60, 60]               0.0050   \n",
              "24             relu                 [60, 60]               0.0100   \n",
              "25             relu                 [60, 60]               0.0100   \n",
              "26             relu                 [60, 60]               0.0100   \n",
              "27             relu                 [60, 60]               0.0100   \n",
              "28             relu                 [60, 60]               0.0100   \n",
              "29             relu                 [60, 60]               0.0100   \n",
              "\n",
              "    param_max_iters param_schedule  \\\n",
              "0               100              1   \n",
              "1               100             10   \n",
              "2               100             25   \n",
              "3               100             50   \n",
              "4               100            100   \n",
              "5               100          10000   \n",
              "6               100              1   \n",
              "7               100             10   \n",
              "8               100             25   \n",
              "9               100             50   \n",
              "10              100            100   \n",
              "11              100          10000   \n",
              "12              100              1   \n",
              "13              100             10   \n",
              "14              100             25   \n",
              "15              100             50   \n",
              "16              100            100   \n",
              "17              100          10000   \n",
              "18              100              1   \n",
              "19              100             10   \n",
              "20              100             25   \n",
              "21              100             50   \n",
              "22              100            100   \n",
              "23              100          10000   \n",
              "24              100              1   \n",
              "25              100             10   \n",
              "26              100             25   \n",
              "27              100             50   \n",
              "28              100            100   \n",
              "29              100          10000   \n",
              "\n",
              "                                               params  split0_test_score  \\\n",
              "0   {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "1   {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "2   {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "3   {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "4   {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "5   {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "6   {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "7   {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "8   {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "9   {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "10  {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "11  {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "12  {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "13  {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "14  {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "15  {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "16  {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "17  {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "18  {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "19  {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "20  {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "21  {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "22  {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "23  {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "24  {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "25  {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "26  {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "27  {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "28  {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "29  {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "\n",
              "    split1_test_score  split2_test_score  split3_test_score  \\\n",
              "0            0.063791           0.059387           0.057925   \n",
              "1            0.063791           0.059387           0.057925   \n",
              "2            0.063791           0.059387           0.057925   \n",
              "3            0.063791           0.059387           0.057925   \n",
              "4            0.063791           0.059387           0.057925   \n",
              "5            0.063791           0.059387           0.057925   \n",
              "6            0.063791           0.059387           0.057925   \n",
              "7            0.063791           0.059387           0.057925   \n",
              "8            0.063791           0.059387           0.057925   \n",
              "9            0.063791           0.059387           0.057925   \n",
              "10           0.063791           0.059387           0.057925   \n",
              "11           0.063791           0.059387           0.057925   \n",
              "12           0.063791           0.059387           0.057925   \n",
              "13           0.063791           0.059387           0.057925   \n",
              "14           0.063791           0.059387           0.057925   \n",
              "15           0.063791           0.059387           0.057925   \n",
              "16           0.063791           0.059387           0.057925   \n",
              "17           0.063791           0.059387           0.057925   \n",
              "18           0.063791           0.059387           0.057925   \n",
              "19           0.063791           0.059387           0.057925   \n",
              "20           0.063791           0.059387           0.057925   \n",
              "21           0.063791           0.059387           0.057925   \n",
              "22           0.063791           0.059387           0.057925   \n",
              "23           0.063791           0.059387           0.057925   \n",
              "24           0.063791           0.059387           0.057925   \n",
              "25           0.063791           0.059387           0.057925   \n",
              "26           0.063791           0.059387           0.057925   \n",
              "27           0.063791           0.059387           0.057925   \n",
              "28           0.063791           0.059387           0.057925   \n",
              "29           0.063791           0.059387           0.057925   \n",
              "\n",
              "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
              "0            0.068448         0.062238        0.003689                1   \n",
              "1            0.068448         0.062238        0.003689                1   \n",
              "2            0.068448         0.062238        0.003689                1   \n",
              "3            0.068448         0.062238        0.003689                1   \n",
              "4            0.068448         0.062238        0.003689                1   \n",
              "5            0.068448         0.062238        0.003689                1   \n",
              "6            0.068448         0.062238        0.003689                1   \n",
              "7            0.068448         0.062238        0.003689                1   \n",
              "8            0.068448         0.062238        0.003689                1   \n",
              "9            0.068448         0.062238        0.003689                1   \n",
              "10           0.068448         0.062238        0.003689                1   \n",
              "11           0.068448         0.062238        0.003689                1   \n",
              "12           0.068448         0.062238        0.003689                1   \n",
              "13           0.068448         0.062238        0.003689                1   \n",
              "14           0.068448         0.062238        0.003689                1   \n",
              "15           0.068448         0.062238        0.003689                1   \n",
              "16           0.068448         0.062238        0.003689                1   \n",
              "17           0.068448         0.062238        0.003689                1   \n",
              "18           0.068448         0.062238        0.003689                1   \n",
              "19           0.068448         0.062238        0.003689                1   \n",
              "20           0.068448         0.062238        0.003689                1   \n",
              "21           0.068448         0.062238        0.003689                1   \n",
              "22           0.068448         0.062238        0.003689                1   \n",
              "23           0.068448         0.062238        0.003689                1   \n",
              "24           0.068448         0.062238        0.003689                1   \n",
              "25           0.068448         0.062238        0.003689                1   \n",
              "26           0.068448         0.062238        0.003689                1   \n",
              "27           0.068448         0.062238        0.003689                1   \n",
              "28           0.068448         0.062238        0.003689                1   \n",
              "29           0.068448         0.062238        0.003689                1   \n",
              "\n",
              "    split0_train_score  split1_train_score  split2_train_score  \\\n",
              "0             0.061765            0.061779            0.062072   \n",
              "1             0.061765            0.061779            0.062072   \n",
              "2             0.061765            0.061779            0.062072   \n",
              "3             0.061765            0.061779            0.062072   \n",
              "4             0.061765            0.061779            0.062072   \n",
              "5             0.061765            0.061779            0.062072   \n",
              "6             0.061765            0.061779            0.062072   \n",
              "7             0.061765            0.061779            0.062072   \n",
              "8             0.061765            0.061779            0.062072   \n",
              "9             0.061765            0.061779            0.062072   \n",
              "10            0.061765            0.061779            0.062072   \n",
              "11            0.061765            0.061779            0.062072   \n",
              "12            0.061765            0.061779            0.062072   \n",
              "13            0.061765            0.061779            0.062072   \n",
              "14            0.061765            0.061779            0.062072   \n",
              "15            0.061765            0.061779            0.062072   \n",
              "16            0.061765            0.061779            0.062072   \n",
              "17            0.061765            0.061779            0.062072   \n",
              "18            0.061765            0.061779            0.062072   \n",
              "19            0.061765            0.061779            0.062072   \n",
              "20            0.061765            0.061779            0.062072   \n",
              "21            0.061765            0.061779            0.062072   \n",
              "22            0.061765            0.061779            0.062072   \n",
              "23            0.061765            0.061779            0.062072   \n",
              "24            0.061765            0.061779            0.062072   \n",
              "25            0.061765            0.061779            0.062072   \n",
              "26            0.061765            0.061779            0.062072   \n",
              "27            0.061765            0.061779            0.062072   \n",
              "28            0.061765            0.061779            0.062072   \n",
              "29            0.061765            0.061779            0.062072   \n",
              "\n",
              "    split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
              "0             0.063234             0.06043          0.061856         0.000894  \n",
              "1             0.063234             0.06043          0.061856         0.000894  \n",
              "2             0.063234             0.06043          0.061856         0.000894  \n",
              "3             0.063234             0.06043          0.061856         0.000894  \n",
              "4             0.063234             0.06043          0.061856         0.000894  \n",
              "5             0.063234             0.06043          0.061856         0.000894  \n",
              "6             0.063234             0.06043          0.061856         0.000894  \n",
              "7             0.063234             0.06043          0.061856         0.000894  \n",
              "8             0.063234             0.06043          0.061856         0.000894  \n",
              "9             0.063234             0.06043          0.061856         0.000894  \n",
              "10            0.063234             0.06043          0.061856         0.000894  \n",
              "11            0.063234             0.06043          0.061856         0.000894  \n",
              "12            0.063234             0.06043          0.061856         0.000894  \n",
              "13            0.063234             0.06043          0.061856         0.000894  \n",
              "14            0.063234             0.06043          0.061856         0.000894  \n",
              "15            0.063234             0.06043          0.061856         0.000894  \n",
              "16            0.063234             0.06043          0.061856         0.000894  \n",
              "17            0.063234             0.06043          0.061856         0.000894  \n",
              "18            0.063234             0.06043          0.061856         0.000894  \n",
              "19            0.063234             0.06043          0.061856         0.000894  \n",
              "20            0.063234             0.06043          0.061856         0.000894  \n",
              "21            0.063234             0.06043          0.061856         0.000894  \n",
              "22            0.063234             0.06043          0.061856         0.000894  \n",
              "23            0.063234             0.06043          0.061856         0.000894  \n",
              "24            0.063234             0.06043          0.061856         0.000894  \n",
              "25            0.063234             0.06043          0.061856         0.000894  \n",
              "26            0.063234             0.06043          0.061856         0.000894  \n",
              "27            0.063234             0.06043          0.061856         0.000894  \n",
              "28            0.063234             0.06043          0.061856         0.000894  \n",
              "29            0.063234             0.06043          0.061856         0.000894  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0ADGTGA0YDt",
        "outputId": "8520b16d-c365-48f9-f274-996cc701ef0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "results[2].head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_activation</th>\n",
              "      <th>param_hidden_layer_sizes</th>\n",
              "      <th>param_learning_rate</th>\n",
              "      <th>param_max_iters</th>\n",
              "      <th>param_schedule</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>split3_train_score</th>\n",
              "      <th>split4_train_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>48.487795</td>\n",
              "      <td>0.515139</td>\n",
              "      <td>0.066798</td>\n",
              "      <td>0.003554</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>48.400264</td>\n",
              "      <td>0.360022</td>\n",
              "      <td>0.061462</td>\n",
              "      <td>0.004883</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100</td>\n",
              "      <td>10</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>48.487125</td>\n",
              "      <td>0.479855</td>\n",
              "      <td>0.058810</td>\n",
              "      <td>0.001101</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100</td>\n",
              "      <td>25</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>48.247758</td>\n",
              "      <td>0.530896</td>\n",
              "      <td>0.062395</td>\n",
              "      <td>0.004121</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100</td>\n",
              "      <td>50</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>48.223431</td>\n",
              "      <td>0.329084</td>\n",
              "      <td>0.060366</td>\n",
              "      <td>0.001721</td>\n",
              "      <td>relu</td>\n",
              "      <td>[60, 60]</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>{'activation': &lt;function relu at 0x7fe2319f2a6...</td>\n",
              "      <td>0.061638</td>\n",
              "      <td>0.063791</td>\n",
              "      <td>0.059387</td>\n",
              "      <td>0.057925</td>\n",
              "      <td>0.068448</td>\n",
              "      <td>0.062238</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061765</td>\n",
              "      <td>0.061779</td>\n",
              "      <td>0.062072</td>\n",
              "      <td>0.063234</td>\n",
              "      <td>0.06043</td>\n",
              "      <td>0.061856</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "0      48.487795      0.515139         0.066798        0.003554   \n",
              "1      48.400264      0.360022         0.061462        0.004883   \n",
              "2      48.487125      0.479855         0.058810        0.001101   \n",
              "3      48.247758      0.530896         0.062395        0.004121   \n",
              "4      48.223431      0.329084         0.060366        0.001721   \n",
              "\n",
              "  param_activation param_hidden_layer_sizes  param_learning_rate  \\\n",
              "0             relu                 [60, 60]               0.0001   \n",
              "1             relu                 [60, 60]               0.0001   \n",
              "2             relu                 [60, 60]               0.0001   \n",
              "3             relu                 [60, 60]               0.0001   \n",
              "4             relu                 [60, 60]               0.0001   \n",
              "\n",
              "   param_max_iters param_schedule  \\\n",
              "0              100              1   \n",
              "1              100             10   \n",
              "2              100             25   \n",
              "3              100             50   \n",
              "4              100            100   \n",
              "\n",
              "                                              params  split0_test_score  \\\n",
              "0  {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "1  {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "2  {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "3  {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "4  {'activation': <function relu at 0x7fe2319f2a6...           0.061638   \n",
              "\n",
              "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
              "0           0.063791           0.059387           0.057925           0.068448   \n",
              "1           0.063791           0.059387           0.057925           0.068448   \n",
              "2           0.063791           0.059387           0.057925           0.068448   \n",
              "3           0.063791           0.059387           0.057925           0.068448   \n",
              "4           0.063791           0.059387           0.057925           0.068448   \n",
              "\n",
              "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
              "0         0.062238        0.003689                1            0.061765   \n",
              "1         0.062238        0.003689                1            0.061765   \n",
              "2         0.062238        0.003689                1            0.061765   \n",
              "3         0.062238        0.003689                1            0.061765   \n",
              "4         0.062238        0.003689                1            0.061765   \n",
              "\n",
              "   split1_train_score  split2_train_score  split3_train_score  \\\n",
              "0            0.061779            0.062072            0.063234   \n",
              "1            0.061779            0.062072            0.063234   \n",
              "2            0.061779            0.062072            0.063234   \n",
              "3            0.061779            0.062072            0.063234   \n",
              "4            0.061779            0.062072            0.063234   \n",
              "\n",
              "   split4_train_score  mean_train_score  std_train_score  \n",
              "0             0.06043          0.061856         0.000894  \n",
              "1             0.06043          0.061856         0.000894  \n",
              "2             0.06043          0.061856         0.000894  \n",
              "3             0.06043          0.061856         0.000894  \n",
              "4             0.06043          0.061856         0.000894  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p7QJrZC0YDw"
      },
      "source": [
        "y_pred = results[3].predict(test_X)\n",
        "print(classification_report(pd.get_dummies(test_y.values.ravel()).values, y_pred))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyXy8R640YDy"
      },
      "source": [
        "y_pred_train = results[3].predict(train_X)\n",
        "print(classification_report(pd.get_dummies(train_y.values.ravel()).values, y_pred_train))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lak2swDV0YD0",
        "outputId": "3a43185e-b9d8-4e10-bbd1-5d1522289347",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "classification_report(pd.get_dummies(test_y.values.ravel()).values, y_pred)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'              precision    recall  f1-score   support\\n\\n           0       0.00      0.00      0.00       980\\n           1       0.22      0.01      0.01      1135\\n           2       0.14      0.05      0.07      1032\\n           3       0.13      0.31      0.18      1010\\n           4       0.26      0.01      0.01       982\\n           5       0.09      0.05      0.07       892\\n           6       0.00      0.00      0.00       958\\n           7       0.14      0.21      0.17      1027\\n           8       0.05      0.00      0.01       974\\n           9       0.07      0.35      0.12      1009\\n\\n   micro avg       0.10      0.10      0.10      9999\\n   macro avg       0.11      0.10      0.06      9999\\nweighted avg       0.11      0.10      0.06      9999\\n samples avg       0.10      0.10      0.10      9999\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g75rqKg8RtuS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}